{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fca426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.utils.labels_mapping import RelabelByModality\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import nibabel as nib\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose, \n",
    "    LoadImaged, \n",
    "    EnsureChannelFirstd,\n",
    "    AsDiscrete,\n",
    "    SaveImaged\n",
    ")\n",
    "\n",
    "from monai.data import DataLoader, Dataset, decollate_batch\n",
    "from monai.networks.nets import UNet\n",
    "from monai.inferers import sliding_window_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85421134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and define preprocessing transforms\n",
    "\n",
    "preprocessing = Compose([\n",
    "    LoadImaged(keys=['image', 'label']),\n",
    "    EnsureChannelFirstd(keys=['image', 'label']),\n",
    "    RelabelByModality(keys=['label'])\n",
    "])\n",
    "\n",
    "test_data = pd.read_csv('../data/processed/test_split.csv')\n",
    "test_data = test_data.drop(columns=['file_name']).rename(columns={'image_path': 'image', 'label_path': 'label'})\n",
    "test_data['image'] = test_data['image'].apply(lambda x: os.path.join('..', x))\n",
    "test_data['label'] = test_data['label'].apply(lambda x: os.path.join('..', x))\n",
    "test_dict = test_data.to_dict('records') # list of dict (one per image) like [{'image':..., 'label':..., 'modality':...}, ...]\n",
    "\n",
    "test_ds = Dataset(data=test_dict, transform=preprocessing)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2421a369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "CHANNELS = (16, 32, 64, 128, 256)\n",
    "NUM_RES_UNITS = 2\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=49,\n",
    "        channels=CHANNELS,\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=NUM_RES_UNITS,\n",
    "        bias=False,\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('../models/unet3d_PatchSize_increased(96-_128)/best_model_fold_1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "612b975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_volume(model, inputs, vol_size=(96, 96, 96), sw_patch_size=4, overlap=0.25):\n",
    "    \"\"\"Infer a 3D image volume using sliding window inference.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        return sliding_window_inference(\n",
    "            inputs = inputs,                    # e.g. a 3D image volume\n",
    "            roi_size = vol_size,                # size of the sliding window\n",
    "            sw_batch_size = sw_patch_size,      # number of sliding windows to process in parallel\n",
    "            predictor = model,                  # the model to run\n",
    "            overlap = overlap                   # amount of overlap between sliding windows\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_pred = Compose([AsDiscrete(argmax=True)]) # argmax the prediction\n",
    "\n",
    "postprocessing = Compose([\n",
    "    RelabelByModality(keys=['pred', 'label'], reverse=True),\n",
    "    SaveImaged(\n",
    "        keys=['pred'],\n",
    "        output_dir='../data/processed/predictions',\n",
    "        output_postfix='pred',\n",
    "        separate_folder=False\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "507c0286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-20 18:00:02,662 INFO image_writer.py:197 - writing: ../data/preprocessed/predictions/topcow_ct_021_preproc_pred.nii.gz\n",
      "2025-10-20 18:00:07,144 INFO image_writer.py:197 - writing: ../data/preprocessed/predictions/topcow_ct_005_preproc_pred.nii.gz\n",
      "2025-10-20 18:00:20,839 INFO image_writer.py:197 - writing: ../data/preprocessed/predictions/topcow_ct_012_preproc_pred.nii.gz\n",
      "2025-10-20 18:00:28,696 INFO image_writer.py:197 - writing: ../data/preprocessed/predictions/topcow_ct_003_preproc_pred.nii.gz\n",
      "2025-10-20 18:00:41,906 INFO image_writer.py:197 - writing: ../data/preprocessed/predictions/topcow_ct_022_preproc_pred.nii.gz\n",
      "2025-10-20 18:00:49,845 INFO image_writer.py:197 - writing: ../data/preprocessed/predictions/topcow_mr_007_preproc_pred.nii.gz\n",
      "2025-10-20 18:00:57,525 INFO image_writer.py:197 - writing: ../data/preprocessed/predictions/topcow_mr_005_preproc_pred.nii.gz\n",
      "2025-10-20 18:01:06,980 INFO image_writer.py:197 - writing: ../data/preprocessed/predictions/topcow_mr_017_preproc_pred.nii.gz\n",
      "2025-10-20 18:01:13,034 INFO image_writer.py:197 - writing: ../data/preprocessed/predictions/topcow_mr_006_preproc_pred.nii.gz\n",
      "2025-10-20 18:01:17,352 INFO image_writer.py:197 - writing: ../data/preprocessed/predictions/topcow_mr_024_preproc_pred.nii.gz\n",
      "2025-10-20 18:01:28,721 INFO image_writer.py:197 - writing: ../data/preprocessed/predictions/topcow_mr_015_preproc_pred.nii.gz\n",
      "2025-10-20 18:01:39,817 INFO image_writer.py:197 - writing: ../data/preprocessed/predictions/topcow_mr_021_preproc_pred.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# Apply model on test set and save predictions\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, test_data in enumerate(test_loader):\n",
    "        inputs, labels = test_data['image'].to(device), test_data['label'].to(device)\n",
    "\n",
    "        outputs = infer_volume(model, inputs, vol_size=(128, 128, 128), sw_patch_size=1, overlap=0.1) # infer the image volume\n",
    "        outputs = [post_pred(i) for i in decollate_batch(outputs)]  # post-process the prediction\n",
    "        \n",
    "        test_data['pred'] = outputs[0]\n",
    "\n",
    "        test_data = postprocessing(test_data)  # post-process and save the prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
